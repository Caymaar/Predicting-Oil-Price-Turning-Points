{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Periodic Power Law (LPPL)\n",
    "\n",
    "The LPPL model is described as below : \n",
    "\n",
    "$$y(t) = A + B(t_c − t)^{\\alpha} + C(t_c − t)^{\\alpha} cos[\\omega ln(t_c − t) + \\phi] \\ \\ \\ \\ (1)$$\n",
    "\n",
    "where $y(t)$ is the oil price at time $t$, $\\alpha$ is the exponential growth, $\\omega$ is the control of the amplitude of the oscillations and A, B, C and $\\phi$ are the parameters with no structural information.\n",
    "\n",
    "Note that in Eq. (1), $t_c$ is a critical time or a turning point, to be predicated.\n",
    "\n",
    "One main feature captured by Eq. (1) is the dampened yet accelerated oscillation in oil price. That is, when $t$\n",
    "approaches $t_c$, the oscillations occur more frequently with a decreasing amplitude. In other words, $(t_c − t)^\\alpha$ is the power law term, which describes the faster than exponential change of the prices owing to positive feedback mechanisms and $(_c − t)^\\alpha cos[\\omega ln(tc −t)+\\phi]$ is the periodic term, which indicates a correction to the power law term and has the symmetry of discrete scale invariance. \n",
    "\n",
    "The most probable time of the turning point is when $t = t_c$, for $t ≥ t_c$.\n",
    "\n",
    "In the above LPPL model, there are seven parameters that need to be optimized, including four nonlinear parameters, $t_c$, $\\omega$, $\\phi$ and $\\alpha$; and three linear parameters, A, B and C. \n",
    "\n",
    "For simplicity, the linear parameters can be directly derived from the given nonlinear parameters by using least square method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f_j = (t_c - t_j)^\\alpha \\ \\ \\ \\ (2)$$\n",
    "\n",
    "$$g_j = (t_c - t_j)^\\alpha \\cos[\\omega ln(t_c - t_j) + \\phi] \\ \\ \\ \\ (3)$$\n",
    "\n",
    "where $t_j$ ($j = 1, 2, ... , J$) with $j$ as a time unit and $J$ is the total time units in an interval, the linear parameters can be calculated using the following equations:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "A \\\\\n",
    "B \\\\\n",
    "C\n",
    "\\end{pmatrix}\n",
    "=\n",
    "[(V^T_{3 \\times J} \\dot V_{J \\times 3})^{-1} (V^T_{3 \\times J} \\dot V_{J \\times 1})]_{3 \\times 1}\n",
    "\\ \\ \\ \\ (4)$$\n",
    "\n",
    "where \n",
    "$\n",
    "V_{J \\times 3} = \n",
    "\\begin{pmatrix}\n",
    " 1 & f_1 & g_1 \\\\ \n",
    " 1 & f_2 & g_2 \\\\ \n",
    " . & . & . \\\\\n",
    " . & . & . \\\\\n",
    " . & . & . \\\\\n",
    " 1 & f_J & g_J \n",
    "\\end{pmatrix}_{J \\times 3}\n",
    "$\n",
    ", which is a matrix with $J$ rows and 3 columns.\n",
    "\n",
    "\n",
    "$\n",
    "Y_{J \\times 1} = \n",
    "\\begin{pmatrix}\n",
    "y(1) \\\\ \n",
    "y(2) \\\\ \n",
    " . \\\\\n",
    " . \\\\\n",
    " . \\\\\n",
    "y(J)\n",
    "\\end{pmatrix}_{J \\times 1}\n",
    "$\n",
    ", which is a column vector with $J$ rows.\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "A \\\\\n",
    "B \\\\\n",
    "C\n",
    "\\end{pmatrix}\n",
    "= \n",
    "\\begin{pmatrix}\n",
    "J & \\sum_{j=1}^{J} f_j & \\sum_{j=1}^{J} g_j \\\\\n",
    "\\sum_{j=1}^{J} f_j & \\sum_{j=1}^{J} f_j^2 & \\sum_{j=1}^{J} f_j g_j \\\\\n",
    "\\sum_{j=1}^{J} g_j & \\sum_{j=1}^{J} f_j g_j & \\sum_{j=1}^{J} g_j^2\n",
    "\\end{pmatrix}^{-1}\n",
    "\\begin{pmatrix}\n",
    "\\sum_{j=1}^{J} y(j) \\\\\n",
    "\\sum_{j=1}^{J} y(j) f_j \\\\\n",
    "\\sum_{j=1}^{J} y(j) g_j\n",
    "\\end{pmatrix}\n",
    "\\ \\ \\ \\ (5)$$\n",
    "\n",
    "This approach is proven to be very stable and able to yield good estimation of the linear parameters A, B and C.\n",
    "\n",
    "linear parameters, $t_c$, $\\omega$, $\\phi$ and $\\alpha$ proves to be more challenging. In fact, it can be proven that searching for the optimal values of the four nonlinear parameters in the LPPL model is an NP-hard problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 0.40892615610661487, B: 0.00932241095608144, C: 0.007352676444861303\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def calculate_f_g(t_c, t, alpha, omega, phi):\n",
    "    \"\"\"\n",
    "    Calculate the vectors f_j and g_j for a given t_c, alpha, omega, and phi.\n",
    "    \"\"\"\n",
    "    f = (t_c - t) ** alpha\n",
    "    g = f * np.cos(omega * np.log(t_c - t) + phi)\n",
    "    return f, g\n",
    "\n",
    "@njit\n",
    "def calculate_linear_parameters(t, y, t_c, alpha, omega, phi):\n",
    "    \"\"\"\n",
    "    Calculate the linear parameters A, B, and C using the LPPL model.\n",
    "    \"\"\"\n",
    "    # Calculate f and g\n",
    "    f, g = calculate_f_g(t_c, t, alpha, omega, phi)\n",
    "    \n",
    "    # Construct the V matrix\n",
    "    V = np.column_stack((np.ones_like(f), f, g))\n",
    "        \n",
    "    # Compute the normal equations\n",
    "    # (V_T @ V)^(-1) @ (V_T @ y)\n",
    "    params = np.linalg.inv(V.T @ V) @ (V.T @ y)  # A, B, C\n",
    "    \n",
    "    return params  # [A, B, C]\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulated data\n",
    "    t = np.linspace(1, 100, 100)  # Time units\n",
    "    y = np.random.rand(100)  # Random example prices\n",
    "\n",
    "    # LPPL parameters\n",
    "    t_c = 120\n",
    "    alpha = 0.5\n",
    "    omega = 10\n",
    "    phi = 0.1\n",
    "\n",
    "    # Calculate A, B, and C\n",
    "    A, B, C = calculate_linear_parameters(t, y, t_c, alpha, omega, phi)\n",
    "    print(f\"A: {A}, B: {B}, C: {C}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this purpose, the multi-population genetic algorithm (MPGA) is employed to search for the optimal parameter values in the LPPL model. The MPGA is one of the most popular heuristic algorithms with the advantages of improving convergence rates and maintaining relatively low mean-square-errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the framework of LPPL Model can be briefly summarized as follows:\n",
    "\n",
    "**Step 1 :** \n",
    "\n",
    "A sample interval is selected for the prediction of a turning point in the future time horizon. The interval is at least four-year long after the previous major turning point in history.\n",
    "\n",
    "**Step 2 :** \n",
    "\n",
    "The sample interval is further divided into over 100 subintervals to avoid the bias of specific sample interval and the impact of selecting a sample interval on the forecast result.\n",
    "\n",
    "**Step 3 :** \n",
    "\n",
    "For each subinterval, the MPGA (multi-population genetic algorithm) is employed to optimize the parameters in the LPPL model. The optimized LPPL model is then used to predict a date in the future when a turning point will occur.\n",
    "\n",
    "**Step 4 :** \n",
    "\n",
    "The Lomb periodogram analysis is conducted to statistically test the predicted turning points obtained by the LPPL models for all subintervals.\n",
    "\n",
    "**Step 5 :** \n",
    "\n",
    "The turning points that are statistically validated by the Lomb periodogram analysis are considered as predicted turning points by the LPPL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Population Genetic Algorithm (MPGA)\n",
    "\n",
    "the MPGA works on multiple populations with the objective to evaluate each subinterval. After the initial populations are produced, if the optimization criteria are not met, new populations are created and the search starts again. \n",
    "\n",
    "The first step of the MPGA is to generate multiple populations. Inspired by the biology concepts of crossover and mutation, each population in the MPGA can be muted into hundreds of chromosomes and each chromosome represents a feasible solution for the four nonlinear parameters in the LPPL model. Based on Eq. (1), the MPGA measures the fitness value of each of chromosomes (i.e., the four nonlinear parameters) generated from all the populations by computing the residual sum of squares (RSS) between the historical oil price at time t or y(t) and the results from the LPPL models:\n",
    "\n",
    "$$\n",
    "RSS_{m,n} = \\sum_{t=1}^{J} \\left( y(t) - A - B (t^{m,n}_c - t)^{\\alpha^{m,n}} - C (t^{m,n}_c - t)^{\\alpha^{m,n}} \\cos \\left[\\omega^{m,n} \\ln (t^{m,n}_c - t) + \\phi^{m,n} \\right] \\right)^2\n",
    "$$\n",
    "\n",
    "where $RSS_{m,n}$ represents the fitness value (RSS) of the $n$-th chromosome in the $m$-th population; $t^{m,n}_c$, $\\omega^{m,n}$, $\\phi^{m,n}$ and $\\alpha^{m,n}$ correspond to the $n$-th chromosome in the $m$-th population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS values: [2024.01035365 2365.59910753]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def predict_price(t, A, B, C, t_c, alpha, omega, phi):\n",
    "    \"\"\"\n",
    "    Predict price using the LPPL model.\n",
    "    \n",
    "    Parameters:\n",
    "    - t : ndarray : Time points\n",
    "    - A, B, C : float : Linear parameters\n",
    "    - t_c : float : Critical time\n",
    "    - alpha : float : Power-law exponent\n",
    "    - omega : float : Angular frequency\n",
    "    - phi : float : Phase\n",
    "\n",
    "    Returns:\n",
    "    - predicted : ndarray : Predicted prices\n",
    "    \"\"\"\n",
    "    # Calculate f and g\n",
    "    f = (t_c - t) ** alpha\n",
    "    g = f * np.cos(omega * np.log(t_c - t) + phi)\n",
    "    \n",
    "    # Predicted price using the LPPL model\n",
    "    predicted = A + B * f + C * g\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "@njit\n",
    "def calculate_rss(y, t, A, B, C, t_c, alpha, omega, phi):\n",
    "    \"\"\"\n",
    "    Calculate the Residual Sum of Squares (RSS) for given parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - y : ndarray : Observed data (prices)\n",
    "    - t : ndarray : Time points\n",
    "    - A, B, C : float : Linear parameters\n",
    "    - t_c : float : Critical time\n",
    "    - alpha : float : Power-law exponent\n",
    "    - omega : float : Angular frequency\n",
    "    - phi : float : Phase\n",
    "    \n",
    "    Returns:\n",
    "    - rss : float : Residual Sum of Squares\n",
    "    \"\"\"\n",
    "    # Predicted price using the LPPL model\n",
    "    predicted = predict_price(t, A, B, C, t_c, alpha, omega, phi)\n",
    "    \n",
    "    # Residual Sum of Squares\n",
    "    rss = np.sum((y - predicted) ** 2)\n",
    "    \n",
    "    return rss\n",
    "\n",
    "@njit\n",
    "def calculate_rss_population(y, t, linear_params, nonlinear_params):\n",
    "    \"\"\"\n",
    "    Calculate the RSS for all chromosomes in a population.\n",
    "    \n",
    "    Parameters:\n",
    "    - y : ndarray : Observed data (prices)\n",
    "    - t : ndarray : Time points\n",
    "    - linear_params : ndarray : Array of linear parameters [A, B, C]\n",
    "    - nonlinear_params : ndarray : Array of nonlinear parameters [[t_c, alpha, omega, phi], ...]\n",
    "    \n",
    "    Returns:\n",
    "    - rss_values : ndarray : RSS values for each chromosome\n",
    "    \"\"\"\n",
    "    num_chromosomes = nonlinear_params.shape[0]\n",
    "    rss_values = np.zeros(num_chromosomes)\n",
    "    \n",
    "    for i in range(num_chromosomes):\n",
    "        t_c, alpha, omega, phi = nonlinear_params[i]\n",
    "        A, B, C = linear_params[i]  # Assuming one set of linear params per chromosome\n",
    "        rss_values[i] = calculate_rss(y, t, A, B, C, t_c, alpha, omega, phi)\n",
    "    \n",
    "    return rss_values\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example data\n",
    "    t = np.linspace(1, 100, 100)  # Time points\n",
    "    y = np.random.rand(100)  # Observed data (random example)\n",
    "\n",
    "    # Example parameters\n",
    "    linear_params = np.array([\n",
    "        [1.0, -0.5, 0.3],  # [A, B, C] for each chromosome\n",
    "        [1.1, -0.4, 0.35]\n",
    "    ])\n",
    "    nonlinear_params = np.array([\n",
    "        [120.0, 0.5, 10.0, 0.1],  # [t_c, alpha, omega, phi] for chromosome 1\n",
    "        [130.0, 0.6, 8.0, 0.15]   # [t_c, alpha, omega, phi] for chromosome 2\n",
    "    ])\n",
    "\n",
    "    # Calculate RSS values\n",
    "    rss_values = calculate_rss_population(y, t, linear_params, nonlinear_params)\n",
    "    print(\"RSS values:\", rss_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each generation, the minimum fitness value and its corresponding chromosome in each population ($\\substack{\\min \\\\ n} (RSS_{m,n})$ for each $m$), and the minimum fitness value in all populations ($\\substack{\\min \\\\ m,n} (RSS_{m,n})$) and its corresponding chromosome are recorded.\n",
    "\n",
    "A new population will be generated by selection, crossover, mutation and re-inserting. Next, the chromosome whose fitness value is the smallest among the $m$-th population ($\\substack{\\min \\\\ n} (RSS_{m,n})$ for each $m$) will substitute the chromosome whose fitness value is the largest among the $m + 1$-th population ($\\substack{\\max \\\\ n} (RSS_{m,n})$ for each $m + 1$). \n",
    "\n",
    "This process is generally referred to as the immigration operation that combines individual populations into a unified entity. After the immigration operation, if the minimum fitness value in a new population ($\\substack{\\min \\\\ n} (RSS_{m,n})$) is less than the corresponding record (i.e., the minimum fitness value and its corresponding chromosome in this population), the records are updated; otherwise, the original records in this population remain. \n",
    "\n",
    "The record of the minimum fitness value of all populations ($\\substack{\\min \\\\ m,n} (RSS_{m,n})$) and the corresponding chromosome are processed in the same way. Finally, if the minimum fitness value of all populations does not change for a given number of consecutive iterations (set to 50 in our computation), or the total number of iterations reaches a given upper bound (set to 500 in our computation), the algorithm terminates and the latest minimum fitness value of all populations and its corresponding chromosome ($t_c$, $\\omega$, $\\phi$ and $\\alpha$) are considered as the outputs of the MPGA. After obtaining the four nonlinear parameters optimized by the MPGA, the three linear parameters can be subsequently derived from Eq. (5). The corresponding LPPL model is thus established. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('WTI_Spot_Price_daily.csv', skiprows=4)\n",
    "y = np.array(data.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best fitness: 9.380458988383156\n",
      "Best chromosome (t_c, alpha, omega, phi): [166.5462943    0.18942639   1.7682024    3.72248052]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def evaluate_population(y, t, linear_params, nonlinear_params):\n",
    "    \"\"\"\n",
    "    Evaluate RSS for each chromosome in a population.\n",
    "    \"\"\"\n",
    "    return calculate_rss_population(y, t, linear_params, nonlinear_params)\n",
    "\n",
    "def initialize_population(pop_size, param_bounds):\n",
    "    \"\"\"\n",
    "    Initialize a population with random chromosomes.\n",
    "    \"\"\"\n",
    "    return np.random.uniform(\n",
    "        low=[bounds[0] for bounds in param_bounds],\n",
    "        high=[bounds[1] for bounds in param_bounds],\n",
    "        size=(pop_size, len(param_bounds))\n",
    "    )\n",
    "\n",
    "def select_parents(population, fitness):\n",
    "    \"\"\"\n",
    "    Perform selection based on fitness (e.g., tournament selection).\n",
    "    \"\"\"\n",
    "    selected = []\n",
    "    for _ in range(len(population)):\n",
    "        i, j = np.random.choice(len(population), 2, replace=False)\n",
    "        selected.append(population[i] if fitness[i] < fitness[j] else population[j])\n",
    "    return np.array(selected)\n",
    "\n",
    "def crossover(parents, crossover_rate):\n",
    "    \"\"\"\n",
    "    Perform crossover to generate offspring.\n",
    "    \"\"\"\n",
    "    offspring = []\n",
    "    for i in range(0, len(parents), 2):\n",
    "        if np.random.rand() < crossover_rate:\n",
    "            crossover_point = np.random.randint(1, parents.shape[1])\n",
    "            offspring.append(np.concatenate((parents[i, :crossover_point], parents[i + 1, crossover_point:])))\n",
    "            offspring.append(np.concatenate((parents[i + 1, :crossover_point], parents[i, crossover_point:])))\n",
    "        else:\n",
    "            offspring.extend([parents[i], parents[i + 1]])\n",
    "    return np.array(offspring)\n",
    "\n",
    "def mutate(offspring, mutation_rate, param_bounds):\n",
    "    \"\"\"\n",
    "    Apply mutation to offspring.\n",
    "    \"\"\"\n",
    "    for i in range(len(offspring)):\n",
    "        if np.random.rand() < mutation_rate:\n",
    "            mutation_point = np.random.randint(offspring.shape[1])\n",
    "            offspring[i, mutation_point] = np.random.uniform(\n",
    "                param_bounds[mutation_point][0], param_bounds[mutation_point][1]\n",
    "            )\n",
    "    return offspring\n",
    "\n",
    "def immigration_operation(populations, fitness_values):\n",
    "    \"\"\"\n",
    "    Perform immigration between populations.\n",
    "    \"\"\"\n",
    "    for m in range(len(populations) - 1):\n",
    "        # Best chromosome in population m\n",
    "        best_index = np.argmin(fitness_values[m])\n",
    "        best_chromosome = populations[m][best_index]\n",
    "\n",
    "        # Worst chromosome in population m+1\n",
    "        worst_index = np.argmax(fitness_values[m + 1])\n",
    "        populations[m + 1][worst_index] = best_chromosome\n",
    "    return populations\n",
    "\n",
    "# MPGA Parameters\n",
    "pop_size = 50\n",
    "num_populations = 5\n",
    "param_bounds = [(100, 200), (0.1, 1), (1, 20), (0, 2 * np.pi)]  # [(t_c), (alpha), (omega), (phi)]\n",
    "crossover_rate = 0.7\n",
    "mutation_rate = 0.1\n",
    "max_iterations = 500\n",
    "stagnation_limit = 50\n",
    "\n",
    "# Initialize populations\n",
    "populations = [initialize_population(pop_size, param_bounds) for _ in range(num_populations)]\n",
    "fitness_records = [np.inf] * num_populations\n",
    "global_best_fitness = np.inf\n",
    "global_best_chromosome = None\n",
    "\n",
    "stagnation_counter = 0\n",
    "iteration = 0\n",
    "\n",
    "while iteration < max_iterations and stagnation_counter < stagnation_limit:\n",
    "    fitness_values = []\n",
    "    for m in range(num_populations):\n",
    "        # Evaluate fitness for current population\n",
    "        fitness = evaluate_population(y, t, linear_params, populations[m])\n",
    "        fitness_values.append(fitness)\n",
    "\n",
    "        # Update local best\n",
    "        min_fitness = np.min(fitness)\n",
    "        if min_fitness < fitness_records[m]:\n",
    "            fitness_records[m] = min_fitness\n",
    "            if min_fitness < global_best_fitness:\n",
    "                global_best_fitness = min_fitness\n",
    "                global_best_chromosome = populations[m][np.argmin(fitness)]\n",
    "\n",
    "    # Check stagnation\n",
    "    if global_best_fitness == fitness_records[0]:\n",
    "        stagnation_counter += 1\n",
    "    else:\n",
    "        stagnation_counter = 0\n",
    "\n",
    "    # Generate new populations with selection, crossover, mutation\n",
    "    new_populations = []\n",
    "    for m in range(num_populations):\n",
    "        parents = select_parents(populations[m], fitness_values[m])\n",
    "        offspring = crossover(parents, crossover_rate)\n",
    "        new_population = mutate(offspring, mutation_rate, param_bounds)\n",
    "        new_populations.append(new_population)\n",
    "\n",
    "    # Perform immigration operation\n",
    "    populations = immigration_operation(new_populations, fitness_values)\n",
    "    iteration += 1\n",
    "\n",
    "# Output the best solution\n",
    "print(\"Best fitness:\", global_best_fitness)\n",
    "print(\"Best chromosome (t_c, alpha, omega, phi):\", global_best_chromosome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of turning point prediction using the Lomb periodogram analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the turning points predicted by the LPPL models, it is necessary to determine whether the frequency ($\\frac{\\omega}{2\\pi}$) obtained from the MPGA (note that $\\omega$ is one of the optimal four nonlinear parameters) and the frequency of $y(t) − A − B(t_c − t)^\\alpha$ are consistent. A test method called the Lomb periodogram analysis is adopted to detect periodic oscillations for $y(t) − A − B(t_c − t)^\\alpha$ and calculate its frequency.\n",
    "\n",
    "There is many existing methods but the Lomb periodogram analysis method is not only able to objectively evaluate the critical time tc or the turning point, but is also suitable for non-uniform time series.\n",
    "\n",
    "The validation process starts with pre-setting the frequency series ($freq_i$) ($i = 1, 2, ... , M$) with $M$ as the length of the pre-given frequency series. For a given frequency $f$, the power spectral density $P(f)$ can be computed by the Lomb periodogram analysis as below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "P(f) = \\frac{1}{2\\sigma^2} \\left\\{\n",
    "\\frac{\\left( \\sum_{j=1}^{J} (x_j - \\bar{x}) \\cos \\left( 2\\pi f (t_j - \\tau) \\right) \\right)^2}{\\sum_{j=1}^{J} \\cos^2 \\left( 2\\pi f (t_j - \\tau) \\right)}\n",
    "+\n",
    "\\frac{\\left( \\sum_{j=1}^{J} (x_j - \\bar{x}) \\sin \\left( 2\\pi f (t_j - \\tau) \\right) \\right)^2}{\\sum_{j=1}^{J} \\sin^2 \\left( 2\\pi f (t_j - \\tau) \\right)}\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "where $$x_j = y_j - A - B(t_c - t_j)^\\alpha$$ \n",
    "\n",
    "at times $t_j$ ($j = 1, 2, ..., J$); \n",
    "\n",
    "$$\\bar{x} = \\frac{1}{J} \\sum_{j=1}^{J} x_j$$ \n",
    "\n",
    "and \n",
    "\n",
    "$$\\sigma^2 = \\frac{1}{J-1} \\sum_{j=1}^{J}(x_j - \\bar{x})^2$$ \n",
    "\n",
    "are respectively the mean and the variance of $x_j$. The time offset, $\\tau$ is calculated by \n",
    "\n",
    "$$\\tau = \\frac{1}{4\\pi f} \\arctan \\frac{\\sum_{j=1}^{J}\\sin(4\\pi f t_j)}{\\sum_{j=1}^{J}\\cos(4\\pi f t_j)}$$\n",
    "\n",
    "Invalid values are then removed from the resulting $P(freq_i)$ series ($i = 1, 2, ... , M$). These invalid values include: 1) $P(f_{mpf})$ corresponding to the most probable frequency $(f_{mpf})$, which is caused by the random series, and inversely proportional to the length of the given frequency series ($J$), $f_{mpf} ≈ 1.5/J$; 2) the $P(freq_i)$ which is smaller than\n",
    "the critical value that is calculated by $z = −ln(1 − (1 − p)^{1/M})$, at\n",
    "the given statistical significance level of p. If there are no valid values\n",
    "in the $P(freq_i)$ series, the Lomb periodogram rejects the conclusion.\n",
    "\n",
    "In other words, the turning points predicted by the LPPL model are\n",
    "not statistically valid. Otherwise the frequency corresponding to the\n",
    "maximum valid values in the $P(freq_i)$ series is the result of the Lomb\n",
    "periodogram test.\n",
    "\n",
    "The Lomb periodogram analysis can be briefly summarized as\n",
    "follows. First, an LPPL model corresponding to each subinterval is\n",
    "obtained. \n",
    "\n",
    "The Lomb periodogram analysis then computes the frequency value based on the periodic oscillations of the LPPL model.\n",
    "If the frequency value is close to the frequency $(\\omega/2\\pi)$ optimized\n",
    "by the MPGA1, the Lomb periodogram analysis concludes that the\n",
    "prediction by the LPPL model is effective. Otherwise, the predicted\n",
    "turning points are invalid and are thus deleted. \n",
    "\n",
    "Eventually only the\n",
    "turning points predicated by the LPPL models that pass the Lomb\n",
    "periodogram test are recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Cushing OK WTI Spot Price FOB  Dollars per Barrel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/9/2024</td>\n",
       "      <td>68.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/6/2024</td>\n",
       "      <td>68.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/5/2024</td>\n",
       "      <td>68.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/4/2024</td>\n",
       "      <td>68.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/3/2024</td>\n",
       "      <td>70.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9801</th>\n",
       "      <td>01/8/1986</td>\n",
       "      <td>25.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9802</th>\n",
       "      <td>01/7/1986</td>\n",
       "      <td>25.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9803</th>\n",
       "      <td>01/6/1986</td>\n",
       "      <td>26.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9804</th>\n",
       "      <td>01/3/1986</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9805</th>\n",
       "      <td>01/2/1986</td>\n",
       "      <td>25.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9806 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Day  Cushing OK WTI Spot Price FOB  Dollars per Barrel\n",
       "0     12/9/2024                                              68.65\n",
       "1     12/6/2024                                              68.58\n",
       "2     12/5/2024                                              68.58\n",
       "3     12/4/2024                                              68.81\n",
       "4     12/3/2024                                              70.15\n",
       "...         ...                                                ...\n",
       "9801  01/8/1986                                              25.87\n",
       "9802  01/7/1986                                              25.85\n",
       "9803  01/6/1986                                              26.53\n",
       "9804  01/3/1986                                              26.00\n",
       "9805  01/2/1986                                              25.56\n",
       "\n",
       "[9806 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import lombscargle\n",
    "from numba import njit\n",
    "\n",
    "# Step 1: Load and Select Data\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the historical price data from a CSV file or other source.\n",
    "    \"\"\"\n",
    "    data = np.loadtxt(file_path, delimiter=',')  # Replace with appropriate loading logic\n",
    "    return data\n",
    "\n",
    "def select_interval(data, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Select a specific time interval for analysis.\n",
    "    \"\"\"\n",
    "    return data[(data[:, 0] >= start_year) & (data[:, 0] <= end_year)]\n",
    "\n",
    "# Step 2: Divide Interval into Subintervals\n",
    "def divide_into_subintervals(data, num_subintervals):\n",
    "    \"\"\"\n",
    "    Divide the selected interval into overlapping subintervals.\n",
    "    \"\"\"\n",
    "    subintervals = []\n",
    "    step_size = len(data) // num_subintervals\n",
    "    for i in range(num_subintervals):\n",
    "        start = i * step_size\n",
    "        end = start + step_size\n",
    "        subintervals.append(data[start:end])\n",
    "    return subintervals\n",
    "\n",
    "# Step 3: Apply MPGA to Optimize LPPL Parameters\n",
    "def optimize_mpga(subinterval):\n",
    "    \"\"\"\n",
    "    Use a Multi-Population Genetic Algorithm (MPGA) to optimize LPPL parameters.\n",
    "    \"\"\"\n",
    "    # Placeholder: Implement MPGA logic (see MPGA code provided earlier)\n",
    "    # Returns the optimized parameters: [t_c, alpha, omega, phi]\n",
    "    pass\n",
    "\n",
    "# Step 4: Validate with Lomb Periodogram\n",
    "def validate_turning_points(predicted_tcs, time_series):\n",
    "    \"\"\"\n",
    "    Use the Lomb-Scargle periodogram to validate predicted turning points.\n",
    "    \"\"\"\n",
    "    # Convert turning points to frequencies for Lomb-Scargle\n",
    "    frequencies = 1 / (predicted_tcs - np.min(predicted_tcs))\n",
    "    power = lombscargle(time_series, frequencies, normalize=True)\n",
    "    return power\n",
    "\n",
    "# Step 5: Aggregate and Analyze Results\n",
    "def aggregate_and_analyze(subintervals, predictions):\n",
    "    \"\"\"\n",
    "    Aggregate predictions across all subintervals and analyze statistical significance.\n",
    "    \"\"\"\n",
    "    # Identify clusters of predictions (group by proximity)\n",
    "    validated_turning_points = []\n",
    "    for t_c in predictions:\n",
    "        # Apply clustering logic or statistical tests\n",
    "        # Placeholder for validation\n",
    "        validated_turning_points.append(t_c)\n",
    "    return validated_turning_points\n",
    "\n",
    "# Main Framework\n",
    "def lppl_framework(file_path, start_year, end_year, num_subintervals):\n",
    "    \"\"\"\n",
    "    Main function to execute the LPPL framework.\n",
    "    \"\"\"\n",
    "    # Step 1: Load and Select Data\n",
    "    data = load_data(file_path)\n",
    "    selected_data = select_interval(data, start_year, end_year)\n",
    "\n",
    "    # Step 2: Divide Data into Subintervals\n",
    "    subintervals = divide_into_subintervals(selected_data, num_subintervals)\n",
    "\n",
    "    # Step 3: Apply MPGA to Each Subinterval\n",
    "    predictions = []\n",
    "    for subinterval in subintervals:\n",
    "        params = optimize_mpga(subinterval)\n",
    "        predictions.append(params[0])  # Append predicted t_c\n",
    "\n",
    "    # Step 4: Validate with Lomb Periodogram\n",
    "    validated_points = validate_turning_points(predictions, selected_data[:, 0])\n",
    "\n",
    "    # Step 5: Aggregate and Analyze Results\n",
    "    turning_points = aggregate_and_analyze(subintervals, validated_points)\n",
    "    return turning_points\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"price_data.csv\"  # Replace with your dataset\n",
    "    start_year = 2004\n",
    "    end_year = 2016\n",
    "    num_subintervals = 120\n",
    "\n",
    "    turning_points = lppl_framework(file_path, start_year, end_year, num_subintervals)\n",
    "    print(\"Predicted Turning Points:\", turning_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('WTI_Spot_Price_daily.csv', skiprows=4)\n",
    "data.columns = ['Date', 'Price']\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "data = data[\"Price\"]\n",
    "\n",
    "\n",
    "class LPPLModel:\n",
    "\n",
    "    def __init__(self, data, optimizers):\n",
    "        self.data = data\n",
    "        self.optimizers = optimizers\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime(\u001b[38;5;241m2023\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime(\u001b[38;5;241m2024\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m22\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcalculate_time_fraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[46], line 11\u001b[0m, in \u001b[0;36mcalculate_time_fraction\u001b[0;34m(start_time, end_time)\u001b[0m\n\u001b[1;32m      8\u001b[0m three_weeks \u001b[38;5;241m=\u001b[39m timedelta(weeks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Calculer la fraction de temps\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m result \u001b[38;5;241m=\u001b[39m (\u001b[43mtime_difference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdays\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.75\u001b[39m) \u001b[38;5;241m/\u001b[39m three_weeks\u001b[38;5;241m.\u001b[39mdays()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def calculate_time_fraction(start_time, end_time):\n",
    "    # Calculer la différence de temps\n",
    "    time_difference = end_time - start_time\n",
    "    \n",
    "    # Convertir 3 semaines en jours\n",
    "    three_weeks = timedelta(weeks=3)\n",
    "    \n",
    "    # Calculer la fraction de temps\n",
    "    result = (time_difference.days() * 0.75) / three_weeks.total_seconds()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Exemple d'utilisation\n",
    "start_time = datetime(2023, 1, 1)\n",
    "end_time = datetime(2024, 1, 22)\n",
    "print(calculate_time_fraction(start_time, end_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.035714285714286"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "365 * 0.75 / 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814400.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_weeks = timedelta(weeks=3)\n",
    "\n",
    "three_weeks.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Algorithm 1.** Pseudo-code of the MPGA to optimize nonlinear parameters.\n",
    "\n",
    "1: Read historical data;\n",
    "\n",
    "2: Set the start time and end time of the sample denoted as $time_{start}$ and $time_{end}$ respectively;\n",
    "\n",
    "3: Predetermine the value ranges of the four nonlinear parameters, $t_c$, $\\omega$, $\\phi$ and $\\alpha$ ($t_c$ is the day after sample to the future 10 years; $\\omega$ is between 0 and 40; $\\phi$ is between $0$ and $2\\pi$; $\\alpha$ is between $0.1$ and $0.9$);\n",
    "\n",
    "4: Predetermine the number of all populations, and let it equal $10$;\n",
    "\n",
    "5: Predetermine population size, and let it equal $100$;\n",
    "\n",
    "6: Predetermine the up bound of the total loop denoted as $MaxGen$, and let it equal 500;\n",
    "\n",
    "7: Predetermine the up bound that the minimum fitness value of all population does not change, denoted as $StopGen$, and let it equal $50$;\n",
    "\n",
    "8: Predetermine the selection probability of each population, and let it equal 0.9;\n",
    "\n",
    "9: Selecting the subintervals from the sample is as follows:\n",
    "\n",
    "10: Predetermine moving step of start time of subintervals, denoted as $delta$, and let it equal the larger of $(time_{end}-time_{start}) \\times 0.75 / (three weeks)$ and three weeks;\n",
    "\n",
    "11: **for** $subinterval_{end} = time_{end}$ : - one week : $time_{end}-$ six weeks **do**\n",
    "\n",
    "12: - **for** $subinterval_{start} = time_{start} : delta : time_{end} - (time_{end} - time_{start})/4$ **do**\n",
    "\n",
    "13: - - Get the subinterval $[subinterval_{start} \\ \\ subinterval_{end}]$ from the sample $[time_{start} \\ \\ time_{end}]$, where $subinterval_{start}$ is the start time of this subinterval; $subinterval_{end}$ is the end time of this subinterval;\n",
    "\n",
    "14: - - Randomly generate the crossover probability of each population between 0.001 and 0.05;\n",
    "\n",
    "15: - - Randomly generate the mutation probability of each population between 0.001 and 0.05;\n",
    "\n",
    "16: - - **for** each population **do**\n",
    "\n",
    "17: - - - Initialize one population, which includes 100 chromosomes;\n",
    "\n",
    "18: - - - Calculate the fitness value of each chromosome, according to Equation 6;\n",
    "\n",
    "19: - - - Find the minimum fitness value of current population;\n",
    "\n",
    "20: - - - Record this minimum fitness value, denoted as $bestObjV$, and its corresponding chromosome;\n",
    "\n",
    "21: - - **end for**\n",
    "\n",
    "22: - - Find and record the minimum fitness value of all populations;\n",
    "\n",
    "23: - - Add two counters, one is used to record the current number of loop, denoted as $gen$, and the other is used to record the number that the minimum fitness value of all populations does not change, denoted as $gen0$. Let $gen$ equal 1, and let $gen0$ equal 0;\n",
    "\n",
    "24: - - **while** $gen0 < StopGen$ and $gen <= MaxGen$ do\n",
    "\n",
    "25: - - - **for** each population **do**\n",
    "\n",
    "26: - - - - Perform the selection, crossover, and mutation and reinserting operation;\n",
    "\n",
    "27: - - - **end for**\n",
    "\n",
    "28: - - - Perform immigration operation;\n",
    "\n",
    "29: - - - Find the minimum fitness value of each population and their corresponding chromosomes in the current loop;\n",
    "\n",
    "30: - - - Find the minimum fitness value of all populations in the current loop, denoted as $newbestObjV$;\n",
    "\n",
    "31: - - - **if** $newbestObjV < bestObjV$ **then**\n",
    "\n",
    "32: - - - - $bestObjV = newbestObjV$;\n",
    "\n",
    "33: - - - - $gen0 = 0$;\n",
    "\n",
    "34: - - - **else**\n",
    "\n",
    "35: - - - - $gen0 = gen0 + 1$\n",
    "\n",
    "36: - - - **end if**\n",
    "\n",
    "37: - - - $gen = gen + 1$;\n",
    "\n",
    "38: - - **end while**\n",
    "\n",
    "39: - - Save $bestObjV$ and its corresponding chromosome under the current subinterval;\n",
    "\n",
    "40: - **end for**\n",
    "\n",
    "41: **end for**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "historical_data.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 313\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    312\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistorical_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Adapté à votre contexte\u001b[39;00m\n\u001b[0;32m--> 313\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmpga_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# \"results\" contiendra une liste de tuples: (sub_start, sub_end, bestObjV, bestChrom)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mprint\u001b[39m(results)\n",
      "Cell \u001b[0;32mIn[7], line 229\u001b[0m, in \u001b[0;36mmpga_optimization\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmpga_optimization\u001b[39m(file_path):\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# Etape 1 & 2\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     sample \u001b[38;5;241m=\u001b[39m select_sample(data, time_start, time_end)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;66;03m# Génération des sous-intervalles\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 123\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(file_path):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# Charger les données : [temps, prix]\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/npyio.py:992\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    990\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(fname)\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 992\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m encoding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    994\u001b[0m         encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/_datasource.py:533\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: historical_data.csv not found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "# ---- Paramètres prédéfinis ----\n",
    "time_start = 2000.0    # année de début (exemple)\n",
    "time_end = 2010.0      # année de fin (exemple)\n",
    "num_populations = 10\n",
    "population_size = 100\n",
    "MaxGen = 500\n",
    "StopGen = 50\n",
    "selection_probability = 0.9\n",
    "\n",
    "# Paramètres non linéaires : [t_c, omega, phi, alpha]\n",
    "param_bounds = {\n",
    "    \"t_c\": (time_end, time_end + 365*10),  # 10 ans après la fin du sample en jours\n",
    "    \"omega\": (0, 40),\n",
    "    \"phi\": (0, 2*np.pi),\n",
    "    \"alpha\": (0.1, 0.9)\n",
    "}\n",
    "\n",
    "@njit\n",
    "def predict_price(t, A, B, C, t_c, alpha, omega, phi):\n",
    "    \"\"\"\n",
    "    Predict price using the LPPL model.\n",
    "    \n",
    "    Parameters:\n",
    "    - t : ndarray : Time points\n",
    "    - A, B, C : float : Linear parameters\n",
    "    - t_c : float : Critical time\n",
    "    - alpha : float : Power-law exponent\n",
    "    - omega : float : Angular frequency\n",
    "    - phi : float : Phase\n",
    "\n",
    "    Returns:\n",
    "    - predicted : ndarray : Predicted prices\n",
    "    \"\"\"\n",
    "    # Calculate f and g\n",
    "    f = (t_c - t) ** alpha\n",
    "    g = f * np.cos(omega * np.log(t_c - t) + phi)\n",
    "    \n",
    "    # Predicted price using the LPPL model\n",
    "    predicted = A + B * f + C * g\n",
    "    \n",
    "    return predicted\n",
    "\n",
    "@njit\n",
    "def calculate_rss(y, t, A, B, C, t_c, alpha, omega, phi):\n",
    "    \"\"\"\n",
    "    Calculate the Residual Sum of Squares (RSS) for given parameters.\n",
    "    \n",
    "    Parameters:\n",
    "    - y : ndarray : Observed data (prices)\n",
    "    - t : ndarray : Time points\n",
    "    - A, B, C : float : Linear parameters\n",
    "    - t_c : float : Critical time\n",
    "    - alpha : float : Power-law exponent\n",
    "    - omega : float : Angular frequency\n",
    "    - phi : float : Phase\n",
    "    \n",
    "    Returns:\n",
    "    - rss : float : Residual Sum of Squares\n",
    "    \"\"\"\n",
    "    # Predicted price using the LPPL model\n",
    "    predicted = predict_price(t, A, B, C, t_c, alpha, omega, phi)\n",
    "    \n",
    "    # Residual Sum of Squares\n",
    "    rss = np.sum((y - predicted) ** 2)\n",
    "    \n",
    "    return rss\n",
    "\n",
    "@njit\n",
    "def calculate_rss_population(y, t, linear_params, nonlinear_params):\n",
    "    \"\"\"\n",
    "    Calculate the RSS for all chromosomes in a population.\n",
    "    \n",
    "    Parameters:\n",
    "    - y : ndarray : Observed data (prices)\n",
    "    - t : ndarray : Time points\n",
    "    - linear_params : ndarray : Array of linear parameters [A, B, C]\n",
    "    - nonlinear_params : ndarray : Array of nonlinear parameters [[t_c, alpha, omega, phi], ...]\n",
    "    \n",
    "    Returns:\n",
    "    - rss_values : ndarray : RSS values for each chromosome\n",
    "    \"\"\"\n",
    "    num_chromosomes = nonlinear_params.shape[0]\n",
    "    rss_values = np.zeros(num_chromosomes)\n",
    "    \n",
    "    for i in range(num_chromosomes):\n",
    "        t_c, alpha, omega, phi = nonlinear_params[i]\n",
    "        A, B, C = linear_params[i]  # Assuming one set of linear params per chromosome\n",
    "        rss_values[i] = calculate_rss(y, t, A, B, C, t_c, alpha, omega, phi)\n",
    "    \n",
    "    return rss_values\n",
    "\n",
    "@njit\n",
    "def calculate_f_g(t_c, t, alpha, omega, phi):\n",
    "    \"\"\"\n",
    "    Calculate the vectors f_j and g_j for a given t_c, alpha, omega, and phi.\n",
    "    \"\"\"\n",
    "    f = (t_c - t) ** alpha\n",
    "    g = f * np.cos(omega * np.log(t_c - t) + phi)\n",
    "    return f, g\n",
    "\n",
    "@njit\n",
    "def calculate_linear_parameters(t, y, t_c, alpha, omega, phi):\n",
    "    \"\"\"\n",
    "    Calculate the linear parameters A, B, and C using the LPPL model.\n",
    "    \"\"\"\n",
    "    # Calculate f and g\n",
    "    f, g = calculate_f_g(t_c, t, alpha, omega, phi)\n",
    "    \n",
    "    # Construct the V matrix\n",
    "    V = np.column_stack((np.ones_like(f), f, g))\n",
    "        \n",
    "    # Compute the normal equations\n",
    "    # (V_T @ V)^(-1) @ (V_T @ y)\n",
    "    params = np.linalg.inv(V.T @ V) @ (V.T @ y)  # A, B, C\n",
    "    \n",
    "    return params  # [A, B, C]\n",
    "\n",
    "def load_data(file_path):\n",
    "    # Charger les données : [temps, prix]\n",
    "    data = np.loadtxt(file_path, delimiter=',')\n",
    "    return data\n",
    "\n",
    "def select_sample(data, time_start, time_end):\n",
    "    # Sélectionne l’échantillon principal\n",
    "    mask = (data[:,0] >= time_start) & (data[:,0] <= time_end)\n",
    "    return data[mask]\n",
    "\n",
    "def equation_6_fitness(chromosome, sub_data):\n",
    "    \"\"\"\n",
    "    Calcule le RSS (fitness) pour un chromosome.\n",
    "    chromosome = [t_c, omega, phi, alpha]\n",
    "    LPPL: y(t) = A + B(t_c - t)^alpha + C(t_c - t)^alpha cos[omega ln(t_c - t) + phi]\n",
    "    A, B, C sont déterminés par Eq (5) après avoir fixé t_c, omega, phi, alpha.\n",
    "    Ici, on suppose que A,B,C sont optimisés en interne ou fournis via une fonction séparée.\n",
    "    \"\"\"\n",
    "    # Implémentation simplifiée. Il faudra :\n",
    "    # 1. Calculer f_j, g_j\n",
    "    # 2. Résoudre Eq(5) pour obtenir A,B,C\n",
    "    # 3. Calculer le RSS\n",
    "    # Code placeholder :\n",
    "    # TODO: Implémenter réellement cette fonction en fonction du LPPL complet.\n",
    "\n",
    "    \n",
    "\n",
    "    t_c, omega, phi, alpha = chromosome\n",
    "\n",
    "    A, B, C = calculate_linear_parameters(t, y, t_c, alpha, omega, phi)\n",
    "\n",
    "\n",
    "\n",
    "    return np.random.rand()  # Placeholder, retourner une valeur aléatoire temporaire\n",
    "\n",
    "def initialize_population(param_bounds, population_size):\n",
    "    low = [v[0] for v in param_bounds.values()]\n",
    "    high = [v[1] for v in param_bounds.values()]\n",
    "    return np.random.uniform(low, high, size=(population_size, len(param_bounds)))\n",
    "\n",
    "def selection(population, fitness):\n",
    "    # Sélection par tournoi simple\n",
    "    selected = []\n",
    "    for _ in range(len(population)):\n",
    "        i, j = np.random.choice(len(population), 2, replace=False)\n",
    "        selected.append(population[i] if fitness[i] < fitness[j] else population[j])\n",
    "    return np.array(selected)\n",
    "\n",
    "def crossover(parents, prob):\n",
    "    offspring = []\n",
    "    for i in range(0, len(parents), 2):\n",
    "        p1, p2 = parents[i], parents[i+1]\n",
    "        if np.random.rand() < prob:\n",
    "            cp = np.random.randint(1, len(p1))\n",
    "            child1 = np.concatenate((p1[:cp], p2[cp:]))\n",
    "            child2 = np.concatenate((p2[:cp], p1[cp:]))\n",
    "            offspring += [child1, child2]\n",
    "        else:\n",
    "            offspring += [p1, p2]\n",
    "    return np.array(offspring)\n",
    "\n",
    "def mutate(offspring, prob, param_bounds):\n",
    "    keys = list(param_bounds.keys())\n",
    "    for i in range(len(offspring)):\n",
    "        if np.random.rand() < prob:\n",
    "            mp = np.random.randint(len(param_bounds))\n",
    "            low, high = param_bounds[keys[mp]]\n",
    "            offspring[i, mp] = np.random.uniform(low, high)\n",
    "    return offspring\n",
    "\n",
    "def immigration_operation(populations, fitness_values):\n",
    "    # Meilleur de la pop m remplace le pire de la pop m+1\n",
    "    for m in range(len(populations) - 1):\n",
    "        f = fitness_values[m]\n",
    "        best_idx = np.argmin(f)\n",
    "        best_chrom = populations[m][best_idx]\n",
    "\n",
    "        # Calculer fitness pour population m+1\n",
    "        f_next = fitness_values[m+1]\n",
    "        worst_idx = np.argmax(f_next)\n",
    "        populations[m+1][worst_idx] = best_chrom\n",
    "    return populations\n",
    "\n",
    "def generate_subintervals(data, time_start, time_end):\n",
    "    \"\"\"\n",
    "    Génère les sous-intervalles suivant la logique du pseudo-code.\n",
    "    - On calcule delta comme le max entre ((time_end - time_start)*0.75/21 jours) et 21 jours.\n",
    "    - subinterval_end varie de time_end à time_end - 6 semaines (42 jours) par pas de 7 jours.\n",
    "    - subinterval_start varie de time_start à time_end-(time_end-time_start)/4 par pas de delta.\n",
    "    \"\"\"\n",
    "    three_weeks = 21.0  # jours\n",
    "    six_weeks = 42.0\n",
    "    one_week = 7.0\n",
    "    total_days = (time_end - time_start)\n",
    "    delta = max((total_days * 0.75) / three_weeks, three_weeks)\n",
    "\n",
    "    subintervals = []\n",
    "    # Pour simplifier, on considère data[:,0] en jours continus\n",
    "    for sub_end in np.arange(time_end, time_end - six_weeks, -one_week):\n",
    "        for sub_start in np.arange(time_start, time_end - total_days/4, delta):\n",
    "            mask = (data[:,0] >= sub_start) & (data[:,0] <= sub_end)\n",
    "            sub_data = data[mask]\n",
    "            if len(sub_data) > 0:\n",
    "                subintervals.append((sub_start, sub_end, sub_data))\n",
    "    return subintervals\n",
    "\n",
    "def mpga_optimization(file_path):\n",
    "    # Etape 1 & 2\n",
    "    data = load_data(file_path)\n",
    "    sample = select_sample(data, time_start, time_end)\n",
    "\n",
    "    # Génération des sous-intervalles\n",
    "    subintervals = generate_subintervals(sample, time_start, time_end)\n",
    "\n",
    "    # Paramètres globaux\n",
    "    best_solutions = []\n",
    "\n",
    "    # Boucle sur les sous-intervalles\n",
    "    for (sub_start, sub_end, sub_data) in subintervals:\n",
    "        # Définir le crossover et mutation probability par population\n",
    "        crossover_prob = np.random.uniform(0.001, 0.05, size=num_populations)\n",
    "        mutation_prob = np.random.uniform(0.001, 0.05, size=num_populations)\n",
    "\n",
    "        # Initialiser les populations\n",
    "        populations = [initialize_population(param_bounds, population_size) for _ in range(num_populations)]\n",
    "\n",
    "        # Calculer fitness initial\n",
    "        fitness_values = []\n",
    "        bestObjV = np.inf\n",
    "        bestChrom = None\n",
    "\n",
    "        for m in range(num_populations):\n",
    "            fit = np.array([equation_6_fitness(ch, sub_data) for ch in populations[m]])\n",
    "            fitness_values.append(fit)\n",
    "            # Minimum fitness pour cette pop\n",
    "            local_min = np.min(fit)\n",
    "            if local_min < bestObjV:\n",
    "                bestObjV = local_min\n",
    "                bestChrom = populations[m][np.argmin(fit)]\n",
    "\n",
    "        # gen, gen0\n",
    "        gen = 1\n",
    "        gen0 = 0\n",
    "\n",
    "        # Boucle du MPGA\n",
    "        while gen0 < StopGen and gen <= MaxGen:\n",
    "            # Opérations génétiques\n",
    "            new_populations = []\n",
    "            new_fitness_values = []\n",
    "\n",
    "            for m in range(num_populations):\n",
    "                # Sélection\n",
    "                fit = fitness_values[m]\n",
    "                selected = selection(populations[m], fit)\n",
    "                # Crossover\n",
    "                offspring = crossover(selected, crossover_prob[m])\n",
    "                # Mutation\n",
    "                mutated = mutate(offspring, mutation_prob[m], param_bounds)\n",
    "                new_populations.append(mutated)\n",
    "\n",
    "            # Immigration\n",
    "            populations = immigration_operation(new_populations, fitness_values)\n",
    "\n",
    "            # Recalculer fitness\n",
    "            fitness_values = []\n",
    "            for m in range(num_populations):\n",
    "                fit = np.array([equation_6_fitness(ch, sub_data) for ch in populations[m]])\n",
    "                fitness_values.append(fit)\n",
    "\n",
    "            # Trouver le meilleur global du loop courant\n",
    "            current_best = np.inf\n",
    "            for m in range(num_populations):\n",
    "                local_min = np.min(fitness_values[m])\n",
    "                if local_min < current_best:\n",
    "                    current_best = local_min\n",
    "\n",
    "            if current_best < bestObjV:\n",
    "                bestObjV = current_best\n",
    "                gen0 = 0\n",
    "            else:\n",
    "                gen0 += 1\n",
    "\n",
    "            gen += 1\n",
    "\n",
    "        # Sauvegarder le résultat pour ce sous-intervalle\n",
    "        best_solutions.append((sub_start, sub_end, bestObjV, bestChrom))\n",
    "\n",
    "    return best_solutions\n",
    "\n",
    "# Exemple d'utilisation\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = \"historical_data.csv\"  # Adapté à votre contexte\n",
    "    results = mpga_optimization(file_path)\n",
    "    # \"results\" contiendra une liste de tuples: (sub_start, sub_end, bestObjV, bestChrom)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
